{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "Train logistic regression with L2 regularization using 5-fold cross-validation to tune the regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../data\"\n",
    "MODELS_DIR = \"../models\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VAL_FILE = os.path.join(DATA_DIR, \"val.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "MODEL_FILE = os.path.join(MODELS_DIR, \"logistic_model.pkl\")\n",
    "PREDICTIONS_FILE = os.path.join(RESULTS_DIR, \"logistic_predictions.csv\")\n",
    "METRICS_FILE = os.path.join(RESULTS_DIR, \"logistic_metrics.json\")\n",
    "\n",
    "TARGET_COL = \"status\"\n",
    "RANDOM_STATE = 42\n",
    "C_VALUES = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (179250, 67)\n",
      "Validation set: (14867, 67)\n",
      "Test set: (14867, 67)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "val_df = pd.read_csv(VAL_FILE)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET_COL])\n",
    "y_train = train_df[TARGET_COL]\n",
    "\n",
    "X_val = val_df.drop(columns=[TARGET_COL])\n",
    "y_val = val_df[TARGET_COL]\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET_COL])\n",
    "y_test = test_df[TARGET_COL]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best parameters: {'C': 100, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "Best CV AUC-ROC: 0.8517\n"
     ]
    }
   ],
   "source": [
    "# Train with 5-fold CV\n",
    "param_grid = {\n",
    "    'C': C_VALUES,\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [1000],\n",
    "    'random_state': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV AUC-ROC: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "AUC-ROC: 0.8418\n",
      "AUC-PR: 0.7709\n",
      "Brier Score: 0.1338\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     11203\n",
      "           1       0.66      0.66      0.66      3664\n",
      "\n",
      "    accuracy                           0.83     14867\n",
      "   macro avg       0.77      0.77      0.77     14867\n",
      "weighted avg       0.83      0.83      0.83     14867\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9965 1238]\n",
      " [1259 2405]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "val_auc_roc = roc_auc_score(y_val, y_val_proba)\n",
    "val_auc_pr = average_precision_score(y_val, y_val_proba)\n",
    "val_brier = brier_score_loss(y_val, y_val_proba)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(f\"AUC-ROC: {val_auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {val_auc_pr:.4f}\")\n",
    "print(f\"Brier Score: {val_brier:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "AUC-ROC: 0.8512\n",
      "AUC-PR: 0.7800\n",
      "Brier Score: 0.1312\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_proba)\n",
    "test_auc_pr = average_precision_score(y_test, y_test_proba)\n",
    "test_brier = brier_score_loss(y_test, y_test_proba)\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(f\"AUC-ROC: {test_auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {test_auc_pr:.4f}\")\n",
    "print(f\"Brier Score: {test_brier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/logistic_model.pkl\n",
      "Predictions saved to ../results/logistic_predictions.csv\n",
      "Metrics saved to ../results/logistic_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "joblib.dump(best_model, MODEL_FILE)\n",
    "print(f\"Model saved to {MODEL_FILE}\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': y_val,\n",
    "    'predicted_probability': y_val_proba,\n",
    "    'predicted_label': y_val_pred,\n",
    "    'dataset': 'validation'\n",
    "})\n",
    "predictions_df.to_csv(PREDICTIONS_FILE, index=False)\n",
    "print(f\"Predictions saved to {PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save metrics\n",
    "all_metrics = {\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'best_cv_score': float(grid_search.best_score_),\n",
    "    'validation_metrics': {\n",
    "        'auc_roc': float(val_auc_roc),\n",
    "        'auc_pr': float(val_auc_pr),\n",
    "        'brier_score': float(val_brier),\n",
    "        'dataset': 'Validation'\n",
    "    },\n",
    "    'test_metrics': {\n",
    "        'auc_roc': float(test_auc_roc),\n",
    "        'auc_pr': float(test_auc_pr),\n",
    "        'brier_score': float(test_brier),\n",
    "        'dataset': 'Test'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(METRICS_FILE, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "print(f\"Metrics saved to {METRICS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
