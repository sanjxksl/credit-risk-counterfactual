{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Model\n",
    "\n",
    "Train a 3-layer neural network using PyTorch with early stopping for loan default prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../data\"\n",
    "MODELS_DIR = \"../models\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VAL_FILE = os.path.join(DATA_DIR, \"val.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "MODEL_FILE = os.path.join(MODELS_DIR, \"mlp_model.pth\")\n",
    "PREDICTIONS_FILE = os.path.join(RESULTS_DIR, \"mlp_predictions.csv\")\n",
    "METRICS_FILE = os.path.join(RESULTS_DIR, \"mlp_metrics.json\")\n",
    "\n",
    "TARGET_COL = \"status\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP architecture\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (179250, 67)\n",
      "Validation set: (14867, 67)\n",
      "Test set: (14867, 67)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "val_df = pd.read_csv(VAL_FILE)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET_COL]).values\n",
    "y_train = train_df[TARGET_COL].values\n",
    "\n",
    "X_val = val_df.drop(columns=[TARGET_COL]).values\n",
    "y_val = val_df[TARGET_COL].values\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET_COL]).values\n",
    "y_test = test_df[TARGET_COL].values\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 19073 parameters\n",
      "Training on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleMLP(input_dim).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Training on device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.4768, Val Loss: 0.3757\n",
      "Epoch 2/50 - Train Loss: 0.4201, Val Loss: 0.3573\n",
      "Epoch 3/50 - Train Loss: 0.4084, Val Loss: 0.3561\n",
      "Epoch 4/50 - Train Loss: 0.4004, Val Loss: 0.3705\n",
      "Epoch 5/50 - Train Loss: 0.3942, Val Loss: 0.3666\n",
      "Epoch 6/50 - Train Loss: 0.3901, Val Loss: 0.3561\n",
      "Epoch 7/50 - Train Loss: 0.3860, Val Loss: 0.3464\n",
      "Epoch 8/50 - Train Loss: 0.3821, Val Loss: 0.3314\n",
      "Epoch 9/50 - Train Loss: 0.3807, Val Loss: 0.3378\n",
      "Epoch 10/50 - Train Loss: 0.3768, Val Loss: 0.3560\n",
      "Epoch 11/50 - Train Loss: 0.3729, Val Loss: 0.3347\n",
      "Epoch 12/50 - Train Loss: 0.3717, Val Loss: 0.3477\n",
      "Epoch 13/50 - Train Loss: 0.3680, Val Loss: 0.3284\n",
      "Epoch 14/50 - Train Loss: 0.3678, Val Loss: 0.3410\n",
      "Epoch 15/50 - Train Loss: 0.3637, Val Loss: 0.3339\n",
      "Epoch 16/50 - Train Loss: 0.3618, Val Loss: 0.3377\n",
      "Epoch 17/50 - Train Loss: 0.3615, Val Loss: 0.3383\n",
      "Epoch 18/50 - Train Loss: 0.3597, Val Loss: 0.3598\n",
      "Early stopping triggered after 18 epochs\n",
      "Best validation loss: 0.3284\n"
     ]
    }
   ],
   "source": [
    "# Train with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{MAX_EPOCHS} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "AUC-ROC: 0.8815\n",
      "AUC-PR: 0.8295\n",
      "Brier Score: 0.1101\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91     11203\n",
      "           1       0.71      0.73      0.72      3664\n",
      "\n",
      "    accuracy                           0.86     14867\n",
      "   macro avg       0.81      0.81      0.81     14867\n",
      "weighted avg       0.86      0.86      0.86     14867\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10109  1094]\n",
      " [ 1006  2658]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val_proba = model(X_val_tensor).cpu().numpy().flatten()\n",
    "\n",
    "y_val_pred = (y_val_proba >= 0.5).astype(int)\n",
    "\n",
    "val_auc_roc = roc_auc_score(y_val, y_val_proba)\n",
    "val_auc_pr = average_precision_score(y_val, y_val_proba)\n",
    "val_brier = brier_score_loss(y_val, y_val_proba)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(f\"AUC-ROC: {val_auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {val_auc_pr:.4f}\")\n",
    "print(f\"Brier Score: {val_brier:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "AUC-ROC: 0.8917\n",
      "AUC-PR: 0.8412\n",
      "Brier Score: 0.1075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_test_proba = model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_proba)\n",
    "test_auc_pr = average_precision_score(y_test, y_test_proba)\n",
    "test_brier = brier_score_loss(y_test, y_test_proba)\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(f\"AUC-ROC: {test_auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {test_auc_pr:.4f}\")\n",
    "print(f\"Brier Score: {test_brier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/mlp_model.pth\n",
      "Predictions saved to ../results/mlp_predictions.csv\n",
      "Metrics saved to ../results/mlp_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_dim': input_dim\n",
    "}, MODEL_FILE)\n",
    "print(f\"Model saved to {MODEL_FILE}\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': y_val,\n",
    "    'predicted_probability': y_val_proba,\n",
    "    'predicted_label': y_val_pred,\n",
    "    'dataset': 'validation'\n",
    "})\n",
    "predictions_df.to_csv(PREDICTIONS_FILE, index=False)\n",
    "print(f\"Predictions saved to {PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save metrics\n",
    "all_metrics = {\n",
    "    'architecture': 'Input → 128 → 64 → 32 → 1',\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'max_epochs': MAX_EPOCHS,\n",
    "    'patience': PATIENCE,\n",
    "    'validation_metrics': {\n",
    "        'auc_roc': float(val_auc_roc),\n",
    "        'auc_pr': float(val_auc_pr),\n",
    "        'brier_score': float(val_brier),\n",
    "        'dataset': 'Validation'\n",
    "    },\n",
    "    'test_metrics': {\n",
    "        'auc_roc': float(test_auc_roc),\n",
    "        'auc_pr': float(test_auc_pr),\n",
    "        'brier_score': float(test_brier),\n",
    "        'dataset': 'Test'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(METRICS_FILE, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "print(f\"Metrics saved to {METRICS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
