{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron Model\n",
    "\n",
    "Train a 3-layer neural network using PyTorch with early stopping for loan default prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:55.385842Z",
     "iopub.status.busy": "2025-12-05T16:02:55.385740Z",
     "iopub.status.idle": "2025-12-05T16:02:57.226672Z",
     "shell.execute_reply": "2025-12-05T16:02:57.226374Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../data\"\n",
    "MODELS_DIR = \"../models\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VAL_FILE = os.path.join(DATA_DIR, \"val.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "MODEL_FILE = os.path.join(MODELS_DIR, \"mlp_model.pth\")\n",
    "PREDICTIONS_FILE = os.path.join(RESULTS_DIR, \"mlp_predictions.csv\")\n",
    "METRICS_FILE = os.path.join(RESULTS_DIR, \"mlp_metrics.json\")\n",
    "\n",
    "TARGET_COL = \"status\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_EPOCHS = 100\n",
    "LEARNING_RATE = 0.002\n",
    "PATIENCE = 10\n",
    "WEIGHT_DECAY = 1e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:57.228517Z",
     "iopub.status.busy": "2025-12-05T16:02:57.228364Z",
     "iopub.status.idle": "2025-12-05T16:02:57.231158Z",
     "shell.execute_reply": "2025-12-05T16:02:57.230929Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define improved MLP architecture\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:57.232504Z",
     "iopub.status.busy": "2025-12-05T16:02:57.232382Z",
     "iopub.status.idle": "2025-12-05T16:02:57.762242Z",
     "shell.execute_reply": "2025-12-05T16:02:57.761817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (179250, 67)\n",
      "Validation set: (14867, 67)\n",
      "Test set: (14867, 67)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "val_df = pd.read_csv(VAL_FILE)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET_COL]).values\n",
    "y_train = train_df[TARGET_COL].values\n",
    "\n",
    "X_val = val_df.drop(columns=[TARGET_COL]).values\n",
    "y_val = val_df[TARGET_COL].values\n",
    "\n",
    "X_test = test_df.drop(columns=[TARGET_COL]).values\n",
    "y_test = test_df[TARGET_COL].values\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:57.785305Z",
     "iopub.status.busy": "2025-12-05T16:02:57.785167Z",
     "iopub.status.idle": "2025-12-05T16:02:57.867480Z",
     "shell.execute_reply": "2025-12-05T16:02:57.865213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:57.873878Z",
     "iopub.status.busy": "2025-12-05T16:02:57.873735Z",
     "iopub.status.idle": "2025-12-05T16:02:58.265294Z",
     "shell.execute_reply": "2025-12-05T16:02:58.265036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 61633 parameters\n",
      "Training on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SanjanaKSL/.pyenv/versions/3.8.20/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = SimpleMLP(input_dim).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "print(f\"Training on device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:58.267042Z",
     "iopub.status.busy": "2025-12-05T16:02:58.266838Z",
     "iopub.status.idle": "2025-12-05T16:02:58.269874Z",
     "shell.execute_reply": "2025-12-05T16:02:58.269656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:02:58.271172Z",
     "iopub.status.busy": "2025-12-05T16:02:58.271069Z",
     "iopub.status.idle": "2025-12-05T16:03:50.612473Z",
     "shell.execute_reply": "2025-12-05T16:03:50.612044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 0.4401, Val Loss: 0.3529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Train Loss: 0.4130, Val Loss: 0.3530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Train Loss: 0.4052, Val Loss: 0.3595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Train Loss: 0.4006, Val Loss: 0.3562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 - Train Loss: 0.3940, Val Loss: 0.3609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Train Loss: 0.3842, Val Loss: 0.3427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Train Loss: 0.3791, Val Loss: 0.3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Train Loss: 0.3775, Val Loss: 0.3446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Train Loss: 0.3750, Val Loss: 0.3484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 - Train Loss: 0.3726, Val Loss: 0.3520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Train Loss: 0.3700, Val Loss: 0.3358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Train Loss: 0.3628, Val Loss: 0.3386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Train Loss: 0.3605, Val Loss: 0.3262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Train Loss: 0.3605, Val Loss: 0.3511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 - Train Loss: 0.3574, Val Loss: 0.3264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Train Loss: 0.3565, Val Loss: 0.3326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Train Loss: 0.3560, Val Loss: 0.3489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Train Loss: 0.3514, Val Loss: 0.3274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Train Loss: 0.3495, Val Loss: 0.3272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 - Train Loss: 0.3469, Val Loss: 0.3214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Train Loss: 0.3471, Val Loss: 0.3149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Train Loss: 0.3465, Val Loss: 0.3248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Train Loss: 0.3461, Val Loss: 0.3218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Train Loss: 0.3453, Val Loss: 0.3285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Train Loss: 0.3447, Val Loss: 0.3210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Train Loss: 0.3424, Val Loss: 0.3459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Train Loss: 0.3418, Val Loss: 0.4011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Train Loss: 0.3395, Val Loss: 0.3154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Train Loss: 0.3410, Val Loss: 0.3620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 - Train Loss: 0.3402, Val Loss: 0.3152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 - Train Loss: 0.3377, Val Loss: 0.3187\n",
      "Early stopping triggered after 31 epochs\n",
      "Best validation loss: 0.3149\n"
     ]
    }
   ],
   "source": [
    "# Train with early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss = validate(model, val_loader, criterion)\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{MAX_EPOCHS} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:03:50.615004Z",
     "iopub.status.busy": "2025-12-05T16:03:50.614856Z",
     "iopub.status.idle": "2025-12-05T16:03:50.648511Z",
     "shell.execute_reply": "2025-12-05T16:03:50.648142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "AUC-ROC: 0.8849\n",
      "AUC-PR: 0.8328\n",
      "Brier Score: 0.0950\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92     11203\n",
      "           1       0.81      0.68      0.74      3664\n",
      "\n",
      "    accuracy                           0.88     14867\n",
      "   macro avg       0.86      0.82      0.83     14867\n",
      "weighted avg       0.88      0.88      0.88     14867\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10629   574]\n",
      " [ 1167  2497]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val_proba = model(X_val_tensor).cpu().numpy().flatten()\n",
    "\n",
    "y_val_pred = (y_val_proba >= 0.5).astype(int)\n",
    "\n",
    "val_auc_roc = roc_auc_score(y_val, y_val_proba)\n",
    "val_auc_pr = average_precision_score(y_val, y_val_proba)\n",
    "val_brier = brier_score_loss(y_val, y_val_proba)\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(f\"AUC-ROC: {val_auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {val_auc_pr:.4f}\")\n",
    "print(f\"Brier Score: {val_brier:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:03:50.650143Z",
     "iopub.status.busy": "2025-12-05T16:03:50.650015Z",
     "iopub.status.idle": "2025-12-05T16:03:50.712431Z",
     "shell.execute_reply": "2025-12-05T16:03:50.712091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "AUC-ROC: 0.8943\n",
      "AUC-PR: 0.8424\n",
      "Brier Score: 0.0917\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_test_proba = model(X_test_tensor).cpu().numpy().flatten()\n",
    "\n",
    "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_proba)\n",
    "test_auc_pr = average_precision_score(y_test, y_test_proba)\n",
    "test_brier = brier_score_loss(y_test, y_test_proba)\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(f\"AUC-ROC: {test_auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {test_auc_pr:.4f}\")\n",
    "print(f\"Brier Score: {test_brier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T16:03:50.714443Z",
     "iopub.status.busy": "2025-12-05T16:03:50.714232Z",
     "iopub.status.idle": "2025-12-05T16:03:50.738961Z",
     "shell.execute_reply": "2025-12-05T16:03:50.738550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/mlp_model.pth\n",
      "Predictions saved to ../results/mlp_predictions.csv\n",
      "Metrics saved to ../results/mlp_metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_dim': input_dim\n",
    "}, MODEL_FILE)\n",
    "print(f\"Model saved to {MODEL_FILE}\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'true_label': y_val,\n",
    "    'predicted_probability': y_val_proba,\n",
    "    'predicted_label': y_val_pred,\n",
    "    'dataset': 'validation'\n",
    "})\n",
    "predictions_df.to_csv(PREDICTIONS_FILE, index=False)\n",
    "print(f\"Predictions saved to {PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save metrics\n",
    "all_metrics = {\n",
    "    'architecture': 'Input → 256 → 128 → 64 → 32 → 1 (with BatchNorm)',\n",
    "    'dropout': '0.4 → 0.4 → 0.3 → 0.2',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "    'max_epochs': MAX_EPOCHS,\n",
    "    'patience': PATIENCE,\n",
    "    'gradient_clipping': 1.0,\n",
    "    'validation_metrics': {\n",
    "        'auc_roc': float(val_auc_roc),\n",
    "        'auc_pr': float(val_auc_pr),\n",
    "        'brier_score': float(val_brier),\n",
    "        'dataset': 'Validation'\n",
    "    },\n",
    "    'test_metrics': {\n",
    "        'auc_roc': float(test_auc_roc),\n",
    "        'auc_pr': float(test_auc_pr),\n",
    "        'brier_score': float(test_brier),\n",
    "        'dataset': 'Test'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(METRICS_FILE, 'w') as f:\n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "print(f\"Metrics saved to {METRICS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
