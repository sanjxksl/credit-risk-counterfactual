{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a667a18",
   "metadata": {},
   "source": [
    "# Assignment 4 â€“ Promotion Response Prediction (Fast Submission Notebook)\n",
    "\n",
    "This notebook is optimized for **runtime** in Google Colab.\n",
    "\n",
    "Speed decisions:\n",
    "- **No GridSearchCV** in the submission run.\n",
    "- Uses a **light but strong** feature set.\n",
    "- Replaces expensive `date.nunique()` frequency with **`txn_cnt`**.\n",
    "- Limits `nunique` features on transactions to **category** and **brand**.\n",
    "\n",
    "**Output:** `predict.csv` with two columns: `id`, `active`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40952dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Install + Imports\n",
    "# =========================\n",
    "!pip -q install pyarrow fastparquet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e7f82",
   "metadata": {},
   "source": [
    "## 1) Mount Google Drive and set paths\n",
    "\n",
    "Place these files in the same folder:\n",
    "\n",
    "- `transactions.parquet`\n",
    "- `promos.parquet`\n",
    "- `train_history.parquet`\n",
    "- `test_history.parquet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc19d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# CHANGE THIS to your folder\n",
    "DATA_DIR = \"/content/drive/MyDrive/RSM8421_Assignment4\"  # <- edit me\n",
    "\n",
    "transactions_path = os.path.join(DATA_DIR, \"transactions.parquet\")\n",
    "promos_path = os.path.join(DATA_DIR, \"promos.parquet\")\n",
    "train_history_path = os.path.join(DATA_DIR, \"train_history.parquet\")\n",
    "test_history_path = os.path.join(DATA_DIR, \"test_history.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b710b",
   "metadata": {},
   "source": [
    "## 2) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336dd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet(transactions_path)\n",
    "promos = pd.read_parquet(promos_path)\n",
    "train_history = pd.read_parquet(train_history_path)\n",
    "test_history = pd.read_parquet(test_history_path)\n",
    "\n",
    "print(\"transactions:\", transactions.shape)\n",
    "print(\"promos:\", promos.shape)\n",
    "print(\"train_history:\", train_history.shape)\n",
    "print(\"test_history:\", test_history.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b8172b",
   "metadata": {},
   "source": [
    "## 3) Column detection helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_existing(df, candidates, name=\"column\"):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise ValueError(\n",
    "        f\"Cannot find {name}. Tried: {candidates}. \"\n",
    "        f\"Available cols: {list(df.columns)[:50]} ...\"\n",
    "    )\n",
    "\n",
    "# customer id column\n",
    "ID_COL = find_first_existing(train_history, [\"id\", \"customer_id\", \"cust_id\"], \"customer id\")\n",
    "\n",
    "# promo key column in history tables (sample notebooks often use 'promo')\n",
    "PROMO_COL = find_first_existing(train_history, [\"promo\", \"offer\", \"promotion\", \"offer_id\"], \"promo key\")\n",
    "\n",
    "# label column\n",
    "Y_COL = find_first_existing(train_history, [\"active\", \"response\", \"responded\", \"label\"], \"label\")\n",
    "\n",
    "print(\"Detected ID_COL:\", ID_COL)\n",
    "print(\"Detected PROMO_COL:\", PROMO_COL)\n",
    "print(\"Detected Y_COL:\", Y_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346dc72",
   "metadata": {},
   "source": [
    "## 4) Fast customer features from transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_COL = find_first_existing(transactions, [\"date\", \"transaction_date\", \"dt\"], \"transaction date\")\n",
    "AMT_COL  = find_first_existing(transactions, [\"amt\", \"amount\", \"spend\", \"sales\"], \"transaction amount\")\n",
    "QTY_COL  = find_first_existing(transactions, [\"qty\", \"quantity\", \"units\"], \"transaction quantity\")\n",
    "\n",
    "# Optional categorical columns (may not exist)\n",
    "CAT_COL = None\n",
    "BRAND_COL = None\n",
    "\n",
    "for c in [\"category\", \"cat\", \"category_id\"]:\n",
    "    if c in transactions.columns:\n",
    "        CAT_COL = c\n",
    "        break\n",
    "\n",
    "for c in [\"brand\", \"brand_id\"]:\n",
    "    if c in transactions.columns:\n",
    "        BRAND_COL = c\n",
    "        break\n",
    "\n",
    "# Keep only needed columns to speed up groupby\n",
    "use_cols = [ID_COL, DATE_COL, AMT_COL, QTY_COL]\n",
    "for opt in [CAT_COL, BRAND_COL]:\n",
    "    if opt is not None:\n",
    "        use_cols.append(opt)\n",
    "\n",
    "transactions = transactions[use_cols].copy()\n",
    "transactions[DATE_COL] = pd.to_datetime(transactions[DATE_COL], errors=\"coerce\")\n",
    "\n",
    "max_date = transactions[DATE_COL].max()\n",
    "transactions[\"last_purchase_days\"] = (max_date - transactions[DATE_COL]).dt.days\n",
    "\n",
    "grp = transactions.groupby(ID_COL, sort=False)\n",
    "\n",
    "agg_dict = {\n",
    "    \"recency\": (\"last_purchase_days\", \"min\"),\n",
    "    \"monetary\": (AMT_COL, \"sum\"),\n",
    "    \"avg_amt\": (AMT_COL, \"mean\"),\n",
    "    \"total_qty\": (QTY_COL, \"sum\"),\n",
    "    \"txn_cnt\": (AMT_COL, \"size\"),  # cheap frequency proxy\n",
    "}\n",
    "\n",
    "if CAT_COL is not None:\n",
    "    agg_dict[\"unique_categories\"] = (CAT_COL, \"nunique\")\n",
    "\n",
    "if BRAND_COL is not None:\n",
    "    agg_dict[\"unique_brands\"] = (BRAND_COL, \"nunique\")\n",
    "\n",
    "trans_features = grp.agg(**agg_dict).reset_index()\n",
    "\n",
    "# Fill missing optional columns if they didn't exist\n",
    "if \"unique_categories\" not in trans_features.columns:\n",
    "    trans_features[\"unique_categories\"] = 0\n",
    "if \"unique_brands\" not in trans_features.columns:\n",
    "    trans_features[\"unique_brands\"] = 0\n",
    "\n",
    "print(\"trans_features:\", trans_features.shape)\n",
    "trans_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df6405",
   "metadata": {},
   "source": [
    "## 5) Merge customer + promo features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a477737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_history.merge(trans_features, on=ID_COL, how=\"left\")\n",
    "predict_features = test_history.merge(trans_features, on=ID_COL, how=\"left\")\n",
    "\n",
    "# promo key in promos table\n",
    "PROMO_KEY_PROMOS = find_first_existing(\n",
    "    promos, [PROMO_COL, \"promo\", \"offer\", \"promotion\", \"offer_id\"], \"promo key in promos\"\n",
    ")\n",
    "\n",
    "features = features.merge(promos, left_on=PROMO_COL, right_on=PROMO_KEY_PROMOS, how=\"left\")\n",
    "predict_features = predict_features.merge(promos, left_on=PROMO_COL, right_on=PROMO_KEY_PROMOS, how=\"left\")\n",
    "\n",
    "print(\"features:\", features.shape)\n",
    "print(\"predict_features:\", predict_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524de82",
   "metadata": {},
   "source": [
    "## 6) Select promo columns + impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fee7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_num_candidates = [\"promoqty\", \"promoval\"]\n",
    "promo_cat_candidates = [\"category\", \"brand\", \"manufacturer\"]\n",
    "\n",
    "promo_num_cols = [c for c in promo_num_candidates if c in features.columns]\n",
    "promo_cat_cols = [c for c in promo_cat_candidates if c in features.columns]\n",
    "\n",
    "print(\"Promo numeric cols:\", promo_num_cols)\n",
    "print(\"Promo categorical cols:\", promo_cat_cols)\n",
    "\n",
    "def impute_basic(df):\n",
    "    if \"recency\" in df.columns:\n",
    "        df[\"recency\"] = df[\"recency\"].fillna(365)\n",
    "\n",
    "    for c in [\"monetary\", \"avg_amt\", \"total_qty\", \"txn_cnt\", \"unique_categories\", \"unique_brands\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(0)\n",
    "\n",
    "    for c in promo_num_cols:\n",
    "        df[c] = df[c].fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "features = impute_basic(features)\n",
    "predict_features = impute_basic(predict_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a1896",
   "metadata": {},
   "source": [
    "## 7) Consistent encoding for categorical promo fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9457a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categoricals(train_df, pred_df, cols):\n",
    "    if not cols:\n",
    "        return train_df, pred_df\n",
    "\n",
    "    combo = pd.concat([train_df[cols], pred_df[cols]], axis=0)\n",
    "\n",
    "    for c in cols:\n",
    "        combo[c] = combo[c].astype(\"category\")\n",
    "        cats = combo[c].cat.categories\n",
    "\n",
    "        train_df[c] = pd.Categorical(train_df[c], categories=cats).codes\n",
    "        pred_df[c]  = pd.Categorical(pred_df[c], categories=cats).codes\n",
    "\n",
    "        # -1 indicates missing/unseen categories\n",
    "        train_df[c] = train_df[c].replace(-1, -1)\n",
    "        pred_df[c]  = pred_df[c].replace(-1, -1)\n",
    "\n",
    "    return train_df, pred_df\n",
    "\n",
    "features, predict_features = encode_categoricals(features, predict_features, promo_cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a551320",
   "metadata": {},
   "source": [
    "## 8) Final feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeaeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = [\n",
    "    \"recency\", \"monetary\", \"txn_cnt\",\n",
    "    \"avg_amt\", \"total_qty\",\n",
    "    \"unique_categories\", \"unique_brands\"\n",
    "]\n",
    "\n",
    "x_cols = [c for c in base_cols if c in features.columns] + promo_num_cols + promo_cat_cols\n",
    "\n",
    "print(\"Final x_cols:\", x_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a60eb9",
   "metadata": {},
   "source": [
    "## 9) Train/validation and fast fixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features[x_cols].copy()\n",
    "y = features[Y_COL].copy()\n",
    "\n",
    "strat = y if y.nunique() == 2 else None\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=strat\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Val size:\", X_val.shape)\n",
    "print(\"Class balance (train):\", y_train.value_counts(normalize=True).round(3).to_dict())\n",
    "\n",
    "best_rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=4,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "val_pred = best_rf_model.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_pred)\n",
    "print(\"Validation ROC AUC:\", round(val_auc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4137e1f",
   "metadata": {},
   "source": [
    "## 10) Fit on all labeled data and generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model.fit(X, y)\n",
    "\n",
    "X_predict = predict_features[x_cols].copy()\n",
    "pred_proba = best_rf_model.predict_proba(X_predict)[:, 1]\n",
    "\n",
    "predict_out = predict_features[[ID_COL]].copy()\n",
    "predict_out.columns = [\"id\"]  # enforce required output name\n",
    "predict_out[\"active\"] = pred_proba\n",
    "\n",
    "print(predict_out.head())\n",
    "print(\"Prediction rows:\", len(predict_out), \"Expected:\", len(test_history))\n",
    "\n",
    "out_path = os.path.join(DATA_DIR, \"predict.csv\")\n",
    "predict_out.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
